{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안녕하세요 투빅스 보충 과제입니다 :)\n",
    "\n",
    "안녕하세요 투빅스 12기 김태한입니다 :)\n",
    "\n",
    "이번 과제는 코로나 바이러스로 예상치 못한 휴식시간이 생겨 여러분의 딥러닝 감을 유지하고자 드리게 되었습니다.  \n",
    "\n",
    "투빅이분들이라면 분명 쉽게 해낼거라 믿습니다!!\n",
    "\n",
    "\n",
    "모르시는 거 있으시면 저 그리고 12기 멘토분들을 많이 많이 괴롭혀주세요!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러분들은 저번 과제로 뉴럴넷 구현을 이미 한번 하셨습니다!  \n",
    "\n",
    "사실 이번 과제의 최종 목적도 뉴럴넷 구현인데요 이미 한번 하셨고 실력들이 워낙 출중하셔서 금방금방 하실수 있으실거에요.  \n",
    "\n",
    "구현에 바로 들어가기에 앞서 전체 네트워크 구조와 각 구성요소의 행렬 차원 및 오차역전파(back propagation) 복습이 1번 과제입니다.  \n",
    "\n",
    "**?** 에 들어갈 수식을 채워주시면 됩니다!!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Shape 정리\n",
    "\n",
    "n : sample_data 수  \n",
    "d : input_dimension  \n",
    "h : hidden_layer_dimension  \n",
    "c : output_dimension  \n",
    "\n",
    "X : input_data  \n",
    "W1 : layer1_weight  \n",
    "b1 : layer1_bias  \n",
    "H : X*W1+b1  \n",
    "A : activation function 거친 value  \n",
    "W2 : layer2_weight  \n",
    "b2 : layer2_bias  \n",
    "S : A*W2+b2  \n",
    "P : softmax 거친 value  \n",
    "\n",
    "**X==(n,d)  \n",
    "W1==(d,h) 채워주세요  \n",
    "b1==(h,)  \n",
    "H==(n,h) 채워주세요  \n",
    "A==(n,h)  \n",
    "W2==(h,c)  \n",
    "b2==(,c) 채워주세요  \n",
    "S==(n,c) 채워주세요  \n",
    "P==(n,c)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix 미분 정리\n",
    "$H = XW+b　　　(n,h) = (n,d)x(d,h)+(h,)$  \n",
    "$L = f(H)$  \n",
    "$\\frac{\\partial L}{\\partial W} = \\frac{\\partial H}{\\partial W} \\times \\frac{\\partial L}{\\partial H} = X^{T}\\frac{\\partial L}{\\partial H}$ 　채워주세요  \n",
    "$\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial H} \\times \\frac{\\partial H}{\\partial X} = \\frac{\\partial L}{\\partial H}W^{T}$ 　채워주세요  \n",
    "$\\frac{\\partial L}{\\partial b} = 1*\\frac{\\partial L}{\\partial H}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Layers Chain Rule 정리\n",
    "**Forward** \n",
    "\n",
    "$H = XW_{1} + b$  \n",
    "$A = ReLU(H)$  \n",
    "$S = AW_{2} + b_{2}$  \n",
    "$P = Softmax(S)$  \n",
    "$L = -LogLikelihood(P)$\n",
    "\n",
    "\n",
    "**Backward**\n",
    "\n",
    "$\\frac{\\partial L}{\\partial S} = P-T$　:　T는 Label  \n",
    "$\\frac{\\partial L}{\\partial W_{2}} = \\frac{\\partial S}{\\partial W_{2}}\\frac{\\partial L}{\\partial S} = A^{T}(P-T)$ 채워주세요  \n",
    "$\\frac{\\partial L}{\\partial b_{2}} = 1*\\frac{\\partial L}{\\partial S} = P-T$  \n",
    "$\\frac{\\partial L}{\\partial A} = \\frac{\\partial L}{\\partial S}\\frac{\\partial S}{\\partial A} = (P-T)W_{2}^{T} $채워주세요  \n",
    "$\\frac{\\partial L}{\\partial H} = \\frac{\\partial A}{\\partial H}\\frac{\\partial L}{\\partial A}$  \n",
    "$\\frac{\\partial L}{\\partial W_{1}} = \\frac{\\partial H}{\\partial W_{1}}\\frac{\\partial L}{\\partial H} = X^{T}\\frac{\\partial L}{\\partial H}$  \n",
    "$\\frac{\\partial L}{\\partial b_{1}} = \\frac{\\partial L}{\\partial H}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같이 드린 파일중 model.py라는 파일이 있을거에요!!!  \n",
    "그 친구의 빈칸을 채워주시면 되겠습니다~!!  \n",
    "model.py의 함수는 assignment3의 모델 만들기에서 사용되니 참고하시면서 채워주시면 도움이 될거에요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 저희가 구현한 모델을 가지고 한번 cifar-10 dataset을 학습해볼게요!!  \n",
    "근데 시작하기에 앞서 pip install keras 를 해주세요!!  \n",
    "\n",
    "3번과제의 목적은 하이퍼파라미터를 튜닝하던 다른방법을 사용하던 해서 마지막에 그림그리기에서 높은 validation accuracy가 나오도록 하는 과제입니다!!  \n",
    "\n",
    "모델을 2층이아니라 본인만의 3층으로 발전시켜도 좋구요 다른 여러가지 방법들이 있겠죠!?!?!?  \n",
    "\n",
    "가장 높은 validation accuracy를 뽑으신 분께 상품을 드리겠습니다아~!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 load\n",
    "\n",
    "keras 프레임워크를 이용하여 데이터를 로드해 옵니다.  \n",
    "32*32*3차원의 데이터를 3072차원으로 바꾸는 것 까지 해드릴게요.\n",
    "필요하면 sklearn.preprocessing의 scaler를 사용해보셔도 좋습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from Model import TwoLayerNet\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(x_train, x_test, y_train, y_test):\n",
    "    #change dtype\n",
    "    x_train = np.array(x_train, dtype=np.float64)\n",
    "    x_test = np.array(x_test, dtype=np.float64)\n",
    "    \n",
    "    #reshaping\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], -1))\n",
    "    \n",
    "    y_train = np.reshape(y_train, (y_train.shape[0],))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0],))\n",
    "        \n",
    "    #normalizing\n",
    "    mean_value = np.mean(x_train, axis=0)\n",
    "    x_train -= mean_value\n",
    "    x_test -= mean_value\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.70756512369792\n",
      "64.1500758911213\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(x_train))\n",
    "print(np.std(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = preprocessing_data(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.856358443959228e-15\n",
      "63.48399818751155\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(x_train))\n",
    "print(np.std(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 너무 많아서 5000개랑 1000개만 사용해보도록 할게요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:5000]\n",
    "y_train = y_train[:5000]\n",
    "x_test = x_test[:1000]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 확인\n",
    "\n",
    "실제 데이터가 어떻게 생겼는지 한번 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -71.71074,  -74.05614,  -69.5538 , ...,   -3.63908,  -33.8503 ,\n",
       "         -42.38186],\n",
       "       [  23.28926,   40.94386,   54.4462 , ...,   16.36092,    7.1497 ,\n",
       "          29.61814],\n",
       "       [ 124.28926,  118.94386,  122.4462 , ...,  -46.63908,  -39.8503 ,\n",
       "         -30.38186],\n",
       "       ...,\n",
       "       [  36.28926,   26.94386,   12.4462 , ...,  -84.63908,  -47.8503 ,\n",
       "         -30.38186],\n",
       "       [  23.28926,   15.94386,   -7.5538 , ...,   67.36092,  121.1497 ,\n",
       "          -0.38186],\n",
       "       [ -85.71074, -104.05614, -111.5538 , ...,   29.36092,   16.1497 ,\n",
       "         -14.38186]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0,\n",
       "       4, 9, 5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6,\n",
       "       0, 9, 3, 9, 7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2,\n",
       "       1, 2, 3, 7, 2, 6, 8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7,\n",
       "       8, 9, 0, 3, 8, 6, 4, 6, 6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7,\n",
       "       4, 0, 6, 2, 1, 3, 0, 4, 2, 7, 8, 3, 1, 2, 8, 0, 8, 3, 5, 2, 4, 1,\n",
       "       8, 9, 1, 2, 9, 7, 2, 9, 6, 5, 6, 3, 8, 7, 6, 2, 5, 2, 8, 9, 6, 0,\n",
       "       0, 5, 2, 9, 5, 4, 2, 1, 6, 6, 8, 4, 8, 4, 5, 0, 9, 9, 9, 8, 9, 9,\n",
       "       3, 7, 5, 0, 0, 5, 2, 2, 3, 8, 6, 3, 4, 0, 5, 8, 0, 1, 7, 2, 8, 8,\n",
       "       7, 8, 5, 1, 8, 7, 1, 3, 0, 5, 7, 9, 7, 4, 5, 9, 8, 0, 7, 9, 8, 2,\n",
       "       7, 6, 9, 4, 3, 9, 6, 4, 7, 6, 5, 1, 5, 8, 8, 0, 4, 0, 5, 5, 1, 1,\n",
       "       8, 9, 0, 3, 1, 9, 2, 2, 5, 3, 9, 9, 4, 0, 3, 0, 0, 9, 8, 1, 5, 7,\n",
       "       0, 8, 2, 4, 7, 0, 2, 3, 6, 3, 8, 5, 0, 3, 4, 3, 9, 0, 6, 1, 0, 9,\n",
       "       1, 0, 7, 9, 1, 2, 6, 9, 3, 4, 6, 0, 0, 6, 6, 6, 3, 2, 6, 1, 8, 2,\n",
       "       1, 6, 8, 6, 8, 0, 4, 0, 7, 7, 5, 5, 3, 5, 2, 3, 4, 1, 7, 5, 4, 6,\n",
       "       1, 9, 3, 6, 6, 9, 3, 8, 0, 7, 2, 6, 2, 5, 8, 5, 4, 6, 8, 9, 9, 1,\n",
       "       0, 2, 2, 7, 3, 2, 8, 0, 9, 5, 8, 1, 9, 4, 1, 3, 8, 1, 4, 7, 9, 4,\n",
       "       2, 7, 0, 7, 0, 6, 6, 9, 0, 9, 2, 8, 7, 2, 2, 5, 1, 2, 6, 2, 9, 6,\n",
       "       2, 3, 0, 3, 9, 8, 7, 8, 8, 4, 0, 1, 8, 2, 7, 9, 3, 6, 1, 9, 0, 7,\n",
       "       3, 7, 4, 5, 0, 0, 2, 9, 3, 4, 0, 6, 2, 5, 3, 7, 3, 7, 2, 5, 3, 1,\n",
       "       1, 4, 9, 9, 5, 7, 5, 0, 2, 2, 2, 9, 7, 3, 9, 4, 3, 5, 4, 6, 5, 6,\n",
       "       1, 4, 3, 4, 4, 3, 7, 8, 3, 7, 8, 0, 5, 7, 6, 0, 5, 4, 8, 6, 8, 5,\n",
       "       5, 9, 9, 9, 5, 0, 1, 0, 8, 1, 1, 8, 0, 2, 2, 0, 4, 6, 5, 4, 9, 4,\n",
       "       7, 9, 9, 4, 5, 6, 6, 1, 5, 3, 8, 9, 5, 8, 5, 7, 0, 7, 0, 5, 0, 0,\n",
       "       4, 6, 9, 0, 9, 5, 6, 6, 6, 2, 9, 0, 1, 7, 6, 7, 5, 9, 1, 6, 2, 5,\n",
       "       5, 5, 8, 5, 9, 4, 6, 4, 3, 2, 0, 7, 6, 2, 2, 3, 9, 7, 9, 2, 6, 7,\n",
       "       1, 3, 6, 6, 8, 9, 7, 5, 4, 0, 8, 4, 0, 9, 3, 4, 8, 9, 6, 9, 2, 6,\n",
       "       1, 4, 7, 3, 5, 3, 8, 5, 0, 2, 1, 6, 4, 3, 3, 9, 6, 9, 8, 8, 5, 8,\n",
       "       6, 6, 2, 1, 7, 7, 1, 2, 7, 9, 9, 4, 4, 1, 2, 5, 6, 8, 7, 6, 8, 3,\n",
       "       0, 5, 5, 3, 0, 7, 9, 1, 3, 4, 4, 5, 3, 9, 5, 6, 9, 2, 1, 1, 4, 1,\n",
       "       9, 4, 7, 6, 3, 8, 9, 0, 1, 3, 6, 3, 6, 3, 2, 0, 3, 1, 0, 5, 9, 6,\n",
       "       4, 8, 9, 6, 9, 6, 3, 0, 3, 2, 2, 7, 8, 3, 8, 2, 7, 5, 7, 2, 4, 8,\n",
       "       7, 4, 2, 9, 8, 8, 6, 8, 8, 7, 4, 3, 3, 8, 4, 9, 4, 8, 8, 1, 8, 2,\n",
       "       1, 3, 6, 5, 4, 2, 7, 9, 9, 4, 1, 4, 1, 3, 2, 7, 0, 7, 9, 7, 6, 6,\n",
       "       2, 5, 9, 2, 9, 1, 2, 2, 6, 8, 2, 1, 3, 6, 6, 0, 1, 2, 7, 0, 5, 4,\n",
       "       6, 1, 6, 4, 0, 2, 2, 6, 0, 5, 9, 1, 7, 6, 7, 0, 3, 9, 6, 8, 3, 0,\n",
       "       3, 4, 7, 7, 1, 4, 7, 2, 7, 1, 4, 7, 4, 4, 8, 4, 7, 7, 5, 3, 7, 2,\n",
       "       0, 8, 9, 5, 8, 3, 6, 2, 0, 8, 7, 3, 7, 6, 5, 3, 1, 3, 2, 2, 5, 4,\n",
       "       1, 2, 9, 2, 7, 0, 7, 2, 1, 3, 2, 0, 2, 4, 7, 9, 8, 9, 0, 7, 7, 0,\n",
       "       7, 8, 4, 6, 3, 3, 0, 1, 3, 7, 0, 1, 3, 1, 4, 2, 3, 8, 4, 2, 3, 7,\n",
       "       8, 4, 3, 0, 9, 0, 0, 1, 0, 4, 4, 6, 7, 6, 1, 1, 3, 7, 3, 5, 2, 6,\n",
       "       6, 5, 8, 7, 1, 6, 8, 8, 5, 3, 0, 4, 0, 1, 3, 8, 8, 0, 6, 9, 9, 9,\n",
       "       5, 5, 8, 6, 0, 0, 4, 2, 3, 2, 7, 2, 2, 5, 9, 8, 9, 1, 7, 4, 0, 3,\n",
       "       0, 1, 3, 8, 3, 9, 6, 1, 4, 7, 0, 3, 7, 8, 9, 1, 1, 6, 6, 6, 6, 9,\n",
       "       1, 9, 9, 4, 2, 1, 7, 0, 6, 8, 1, 9, 2, 9, 0, 4, 7, 8, 3, 1, 2, 0,\n",
       "       1, 5, 8, 4, 6, 3, 8, 1, 3, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 설정\n",
    "\n",
    "이제 하이퍼파라미터를 설정해볼게요.  \n",
    "hidden_size, epoch_size, batch_size, learning_rate등은 전부 하이퍼 파라미터이니 바꾸면서 도전해보세요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 512 #hidden size는 2의 거듭제곱 형태로 지정해주는 것이 좋다고 한다.\n",
    "output_size = 10 #cifar 데이터의 클래스는 10개이다.\n",
    "epoch_size = 3000 #학습을 얼마나 할 것인지에 대한 것이다. 너무 많이해도 다시 Loss가 오르는 모습을 볼 수 있다.\n",
    "batch_size = 250 #학습 한 번 할때 데이터 몇 개씩 넣을 것인지에 대한 값으로 하이퍼 파라미터 튜닝 시 크게 상관은 없다고 한다.\n",
    "learning_rate = 0.0001 #learning _rate는 작을 수록 좋지만 너무 작으면 컴퓨터가 0으로 인식하기 때문에 주의하여야 한다.\n",
    "N = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 만들기\n",
    "\n",
    "input_size, hidden_size, output_size는 데이터에 맞게 잘 설정해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mask = np.random.choice(N, batch_size) #이번 배치에서 쓸 데이터들 인덱스 추출\n",
    "x_batch = x_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = TwoLayerNet(x_batch, input_size=input_size, hidden_size=hidden_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 test accuracy : 0.103\n",
      "0 test loss     : 2485.6816757324705\n",
      "10 test accuracy : 0.103\n",
      "10 test loss     : 2432.9441432672115\n",
      "20 test accuracy : 0.101\n",
      "20 test loss     : 2332.640878538796\n",
      "30 test accuracy : 0.158\n",
      "30 test loss     : 2253.8040759235896\n",
      "40 test accuracy : 0.2\n",
      "40 test loss     : 2194.458907327762\n",
      "50 test accuracy : 0.239\n",
      "50 test loss     : 2139.864170420053\n",
      "60 test accuracy : 0.268\n",
      "60 test loss     : 2088.3457562519234\n",
      "70 test accuracy : 0.284\n",
      "70 test loss     : 2042.0253727901518\n",
      "80 test accuracy : 0.294\n",
      "80 test loss     : 2004.8676759742882\n",
      "90 test accuracy : 0.307\n",
      "90 test loss     : 1973.9792585669977\n",
      "100 test accuracy : 0.307\n",
      "100 test loss     : 1947.1053858675998\n",
      "110 test accuracy : 0.316\n",
      "110 test loss     : 1923.7764093479393\n",
      "120 test accuracy : 0.313\n",
      "120 test loss     : 1904.7554722169023\n",
      "130 test accuracy : 0.323\n",
      "130 test loss     : 1887.4067634145363\n",
      "140 test accuracy : 0.331\n",
      "140 test loss     : 1871.9463783380152\n",
      "150 test accuracy : 0.332\n",
      "150 test loss     : 1858.1544175069812\n",
      "160 test accuracy : 0.329\n",
      "160 test loss     : 1844.9647597046878\n",
      "170 test accuracy : 0.337\n",
      "170 test loss     : 1832.2532182636053\n",
      "180 test accuracy : 0.35\n",
      "180 test loss     : 1820.6997878319817\n",
      "190 test accuracy : 0.354\n",
      "190 test loss     : 1808.8970817415889\n",
      "200 test accuracy : 0.35\n",
      "200 test loss     : 1799.3748382847198\n",
      "210 test accuracy : 0.356\n",
      "210 test loss     : 1789.8278687179302\n",
      "220 test accuracy : 0.358\n",
      "220 test loss     : 1780.9338220319057\n",
      "230 test accuracy : 0.357\n",
      "230 test loss     : 1772.2010145801692\n",
      "240 test accuracy : 0.364\n",
      "240 test loss     : 1763.1573931971798\n",
      "250 test accuracy : 0.364\n",
      "250 test loss     : 1753.8964072863257\n",
      "260 test accuracy : 0.362\n",
      "260 test loss     : 1746.1176096657405\n",
      "270 test accuracy : 0.364\n",
      "270 test loss     : 1739.976410539358\n",
      "280 test accuracy : 0.362\n",
      "280 test loss     : 1732.4992988422057\n",
      "290 test accuracy : 0.365\n",
      "290 test loss     : 1725.2729078867394\n",
      "300 test accuracy : 0.367\n",
      "300 test loss     : 1718.646266403911\n",
      "310 test accuracy : 0.366\n",
      "310 test loss     : 1712.993470697631\n",
      "320 test accuracy : 0.37\n",
      "320 test loss     : 1708.5135254032666\n",
      "330 test accuracy : 0.376\n",
      "330 test loss     : 1703.9901212246066\n",
      "340 test accuracy : 0.374\n",
      "340 test loss     : 1698.8193736851485\n",
      "350 test accuracy : 0.378\n",
      "350 test loss     : 1694.8885539967105\n",
      "360 test accuracy : 0.382\n",
      "360 test loss     : 1690.0279278506523\n",
      "370 test accuracy : 0.387\n",
      "370 test loss     : 1685.7936190780706\n",
      "380 test accuracy : 0.392\n",
      "380 test loss     : 1681.1576026980742\n",
      "390 test accuracy : 0.398\n",
      "390 test loss     : 1677.4717890747643\n",
      "400 test accuracy : 0.397\n",
      "400 test loss     : 1674.3376559260705\n",
      "410 test accuracy : 0.396\n",
      "410 test loss     : 1671.3622276225922\n",
      "420 test accuracy : 0.394\n",
      "420 test loss     : 1667.0181859656082\n",
      "430 test accuracy : 0.402\n",
      "430 test loss     : 1665.4061644754952\n",
      "440 test accuracy : 0.397\n",
      "440 test loss     : 1662.0484591487157\n",
      "450 test accuracy : 0.395\n",
      "450 test loss     : 1659.965404322306\n",
      "460 test accuracy : 0.4\n",
      "460 test loss     : 1655.8244575028962\n",
      "470 test accuracy : 0.404\n",
      "470 test loss     : 1652.4920707901156\n",
      "480 test accuracy : 0.404\n",
      "480 test loss     : 1648.6572069296333\n",
      "490 test accuracy : 0.4\n",
      "490 test loss     : 1646.308466591443\n",
      "500 test accuracy : 0.401\n",
      "500 test loss     : 1644.7057820316406\n",
      "510 test accuracy : 0.404\n",
      "510 test loss     : 1641.3095007559807\n",
      "520 test accuracy : 0.395\n",
      "520 test loss     : 1640.657823870737\n",
      "530 test accuracy : 0.399\n",
      "530 test loss     : 1636.2909499397738\n",
      "540 test accuracy : 0.397\n",
      "540 test loss     : 1636.2820361801266\n",
      "550 test accuracy : 0.397\n",
      "550 test loss     : 1634.2744358104499\n",
      "560 test accuracy : 0.394\n",
      "560 test loss     : 1630.849035744092\n",
      "570 test accuracy : 0.403\n",
      "570 test loss     : 1631.431574173289\n",
      "580 test accuracy : 0.401\n",
      "580 test loss     : 1630.5227545933117\n",
      "590 test accuracy : 0.4\n",
      "590 test loss     : 1628.903099661393\n",
      "600 test accuracy : 0.399\n",
      "600 test loss     : 1626.8001182533778\n",
      "610 test accuracy : 0.406\n",
      "610 test loss     : 1624.4553723706513\n",
      "620 test accuracy : 0.401\n",
      "620 test loss     : 1623.5333662011567\n",
      "630 test accuracy : 0.404\n",
      "630 test loss     : 1621.8088764038553\n",
      "640 test accuracy : 0.403\n",
      "640 test loss     : 1620.8999746062725\n",
      "650 test accuracy : 0.404\n",
      "650 test loss     : 1620.1929000494404\n",
      "660 test accuracy : 0.408\n",
      "660 test loss     : 1617.8433188661518\n",
      "670 test accuracy : 0.406\n",
      "670 test loss     : 1619.1434243533977\n",
      "680 test accuracy : 0.41\n",
      "680 test loss     : 1617.1753856463279\n",
      "690 test accuracy : 0.415\n",
      "690 test loss     : 1617.423794257067\n",
      "700 test accuracy : 0.407\n",
      "700 test loss     : 1617.238859073942\n",
      "710 test accuracy : 0.411\n",
      "710 test loss     : 1616.1267320563054\n",
      "720 test accuracy : 0.406\n",
      "720 test loss     : 1616.0130986977786\n",
      "730 test accuracy : 0.407\n",
      "730 test loss     : 1614.8843497703756\n",
      "740 test accuracy : 0.408\n",
      "740 test loss     : 1616.6510037206872\n",
      "750 test accuracy : 0.408\n",
      "750 test loss     : 1615.1088998872162\n",
      "760 test accuracy : 0.413\n",
      "760 test loss     : 1613.779071719735\n",
      "770 test accuracy : 0.413\n",
      "770 test loss     : 1614.4009481573316\n",
      "780 test accuracy : 0.414\n",
      "780 test loss     : 1615.3888307804862\n",
      "790 test accuracy : 0.417\n",
      "790 test loss     : 1613.561973145918\n",
      "800 test accuracy : 0.414\n",
      "800 test loss     : 1616.2477422888098\n",
      "810 test accuracy : 0.407\n",
      "810 test loss     : 1615.4519684802374\n",
      "820 test accuracy : 0.415\n",
      "820 test loss     : 1614.9642271986738\n",
      "830 test accuracy : 0.418\n",
      "830 test loss     : 1615.9718321335151\n",
      "840 test accuracy : 0.417\n",
      "840 test loss     : 1617.116156062071\n",
      "850 test accuracy : 0.415\n",
      "850 test loss     : 1618.8345691034933\n",
      "860 test accuracy : 0.418\n",
      "860 test loss     : 1616.7033260395895\n",
      "870 test accuracy : 0.416\n",
      "870 test loss     : 1619.0284680447062\n",
      "880 test accuracy : 0.413\n",
      "880 test loss     : 1619.3940130408694\n",
      "890 test accuracy : 0.417\n",
      "890 test loss     : 1620.4843423432148\n",
      "900 test accuracy : 0.42\n",
      "900 test loss     : 1620.1123781030194\n",
      "910 test accuracy : 0.419\n",
      "910 test loss     : 1622.4331399928694\n",
      "920 test accuracy : 0.423\n",
      "920 test loss     : 1625.699675156745\n",
      "930 test accuracy : 0.419\n",
      "930 test loss     : 1626.646762045223\n",
      "940 test accuracy : 0.419\n",
      "940 test loss     : 1625.6191751381816\n",
      "950 test accuracy : 0.421\n",
      "950 test loss     : 1627.7524750653943\n",
      "960 test accuracy : 0.42\n",
      "960 test loss     : 1627.5659936272366\n",
      "970 test accuracy : 0.419\n",
      "970 test loss     : 1626.9610421034274\n",
      "980 test accuracy : 0.421\n",
      "980 test loss     : 1634.0446966457514\n",
      "990 test accuracy : 0.417\n",
      "990 test loss     : 1632.07680054929\n",
      "1000 test accuracy : 0.423\n",
      "1000 test loss     : 1636.0182079439703\n",
      "1010 test accuracy : 0.418\n",
      "1010 test loss     : 1637.4885062109684\n",
      "1020 test accuracy : 0.419\n",
      "1020 test loss     : 1637.5561318434075\n",
      "1030 test accuracy : 0.421\n",
      "1030 test loss     : 1637.3606368493843\n",
      "1040 test accuracy : 0.426\n",
      "1040 test loss     : 1638.4302038425462\n",
      "1050 test accuracy : 0.417\n",
      "1050 test loss     : 1643.017901660175\n",
      "1060 test accuracy : 0.419\n",
      "1060 test loss     : 1644.0690376944774\n",
      "1070 test accuracy : 0.422\n",
      "1070 test loss     : 1645.970940845837\n",
      "1080 test accuracy : 0.421\n",
      "1080 test loss     : 1646.9053312809897\n",
      "1090 test accuracy : 0.421\n",
      "1090 test loss     : 1650.5452027975196\n",
      "1100 test accuracy : 0.419\n",
      "1100 test loss     : 1651.2389387571095\n",
      "1110 test accuracy : 0.425\n",
      "1110 test loss     : 1652.8999848080832\n",
      "1120 test accuracy : 0.423\n",
      "1120 test loss     : 1656.2747591760333\n",
      "1130 test accuracy : 0.424\n",
      "1130 test loss     : 1657.1108113675343\n",
      "1140 test accuracy : 0.425\n",
      "1140 test loss     : 1655.8815535691515\n",
      "1150 test accuracy : 0.429\n",
      "1150 test loss     : 1661.527730381575\n",
      "1160 test accuracy : 0.425\n",
      "1160 test loss     : 1664.458697765582\n",
      "1170 test accuracy : 0.424\n",
      "1170 test loss     : 1665.8947402443696\n",
      "1180 test accuracy : 0.423\n",
      "1180 test loss     : 1671.2612773673932\n",
      "1190 test accuracy : 0.424\n",
      "1190 test loss     : 1671.99252950863\n",
      "1200 test accuracy : 0.428\n",
      "1200 test loss     : 1674.6204581264858\n",
      "1210 test accuracy : 0.421\n",
      "1210 test loss     : 1683.628075443711\n",
      "1220 test accuracy : 0.423\n",
      "1220 test loss     : 1683.037165003661\n",
      "1230 test accuracy : 0.423\n",
      "1230 test loss     : 1686.776621811175\n",
      "1240 test accuracy : 0.425\n",
      "1240 test loss     : 1688.3026755048877\n",
      "1250 test accuracy : 0.428\n",
      "1250 test loss     : 1693.01020342822\n",
      "1260 test accuracy : 0.426\n",
      "1260 test loss     : 1695.5569878265153\n",
      "1270 test accuracy : 0.426\n",
      "1270 test loss     : 1697.7148962625336\n",
      "1280 test accuracy : 0.42\n",
      "1280 test loss     : 1702.9877629068203\n",
      "1290 test accuracy : 0.423\n",
      "1290 test loss     : 1702.6294666317503\n",
      "1300 test accuracy : 0.421\n",
      "1300 test loss     : 1706.2705675421994\n",
      "1310 test accuracy : 0.428\n",
      "1310 test loss     : 1711.6598324830445\n",
      "1320 test accuracy : 0.422\n",
      "1320 test loss     : 1716.020441092824\n",
      "1330 test accuracy : 0.427\n",
      "1330 test loss     : 1717.460467839556\n",
      "1340 test accuracy : 0.423\n",
      "1340 test loss     : 1721.7654487975174\n",
      "1350 test accuracy : 0.431\n",
      "1350 test loss     : 1723.3335827451622\n",
      "1360 test accuracy : 0.421\n",
      "1360 test loss     : 1728.4765005350948\n",
      "1370 test accuracy : 0.425\n",
      "1370 test loss     : 1734.6870498595622\n",
      "1380 test accuracy : 0.425\n",
      "1380 test loss     : 1736.6254296952497\n",
      "1390 test accuracy : 0.424\n",
      "1390 test loss     : 1744.3376263961775\n",
      "1400 test accuracy : 0.429\n",
      "1400 test loss     : 1746.652377624063\n",
      "1410 test accuracy : 0.433\n",
      "1410 test loss     : 1747.8944644183246\n",
      "1420 test accuracy : 0.428\n",
      "1420 test loss     : 1754.160773584521\n",
      "1430 test accuracy : 0.43\n",
      "1430 test loss     : 1754.9026863734832\n",
      "1440 test accuracy : 0.425\n",
      "1440 test loss     : 1760.200946254282\n",
      "1450 test accuracy : 0.429\n",
      "1450 test loss     : 1765.3235916959381\n",
      "1460 test accuracy : 0.431\n",
      "1460 test loss     : 1768.9277135620644\n",
      "1470 test accuracy : 0.425\n",
      "1470 test loss     : 1771.1773528619954\n",
      "1480 test accuracy : 0.427\n",
      "1480 test loss     : 1779.2300072895694\n",
      "1490 test accuracy : 0.426\n",
      "1490 test loss     : 1782.897479344793\n",
      "1500 test accuracy : 0.424\n",
      "1500 test loss     : 1787.0778052757726\n",
      "1510 test accuracy : 0.422\n",
      "1510 test loss     : 1792.1894904516473\n",
      "1520 test accuracy : 0.428\n",
      "1520 test loss     : 1797.9226347069903\n",
      "1530 test accuracy : 0.421\n",
      "1530 test loss     : 1798.6935480863765\n",
      "1540 test accuracy : 0.425\n",
      "1540 test loss     : 1800.0081747041756\n",
      "1550 test accuracy : 0.42\n",
      "1550 test loss     : 1807.2589808785194\n",
      "1560 test accuracy : 0.424\n",
      "1560 test loss     : 1810.613060671118\n",
      "1570 test accuracy : 0.419\n",
      "1570 test loss     : 1816.4044234847481\n",
      "1580 test accuracy : 0.426\n",
      "1580 test loss     : 1820.3378627368588\n",
      "1590 test accuracy : 0.425\n",
      "1590 test loss     : 1823.4145389262872\n",
      "1600 test accuracy : 0.421\n",
      "1600 test loss     : 1828.1616119247403\n",
      "1610 test accuracy : 0.42\n",
      "1610 test loss     : 1834.3841908927602\n",
      "1620 test accuracy : 0.419\n",
      "1620 test loss     : 1839.4827065127874\n",
      "1630 test accuracy : 0.421\n",
      "1630 test loss     : 1841.7886055831161\n",
      "1640 test accuracy : 0.421\n",
      "1640 test loss     : 1848.5998481569113\n",
      "1650 test accuracy : 0.418\n",
      "1650 test loss     : 1854.8098821026358\n",
      "1660 test accuracy : 0.418\n",
      "1660 test loss     : 1855.741283982131\n",
      "1670 test accuracy : 0.42\n",
      "1670 test loss     : 1860.9976515546286\n",
      "1680 test accuracy : 0.418\n",
      "1680 test loss     : 1865.1994882132074\n",
      "1690 test accuracy : 0.421\n",
      "1690 test loss     : 1868.2623869140905\n",
      "1700 test accuracy : 0.417\n",
      "1700 test loss     : 1874.980423322579\n",
      "1710 test accuracy : 0.417\n",
      "1710 test loss     : 1879.834684013935\n",
      "1720 test accuracy : 0.419\n",
      "1720 test loss     : 1879.0138710549263\n",
      "1730 test accuracy : 0.418\n",
      "1730 test loss     : 1883.8250566567617\n",
      "1740 test accuracy : 0.417\n",
      "1740 test loss     : 1890.6118258754163\n",
      "1750 test accuracy : 0.418\n",
      "1750 test loss     : 1897.7330088927295\n",
      "1760 test accuracy : 0.421\n",
      "1760 test loss     : 1900.0785416580522\n",
      "1770 test accuracy : 0.417\n",
      "1770 test loss     : 1904.0615563819035\n",
      "1780 test accuracy : 0.419\n",
      "1780 test loss     : 1908.9694657200698\n",
      "1790 test accuracy : 0.42\n",
      "1790 test loss     : 1911.8506833554886\n",
      "1800 test accuracy : 0.421\n",
      "1800 test loss     : 1916.7571812191097\n",
      "1810 test accuracy : 0.42\n",
      "1810 test loss     : 1923.42392368996\n",
      "1820 test accuracy : 0.412\n",
      "1820 test loss     : 1929.5319827810454\n",
      "1830 test accuracy : 0.42\n",
      "1830 test loss     : 1930.9265851412952\n",
      "1840 test accuracy : 0.419\n",
      "1840 test loss     : 1932.1706573236825\n",
      "1850 test accuracy : 0.42\n",
      "1850 test loss     : 1937.9595416645311\n",
      "1860 test accuracy : 0.417\n",
      "1860 test loss     : 1947.310320604686\n",
      "1870 test accuracy : 0.415\n",
      "1870 test loss     : 1950.5891211640094\n",
      "1880 test accuracy : 0.417\n",
      "1880 test loss     : 1954.2952733853783\n",
      "1890 test accuracy : 0.415\n",
      "1890 test loss     : 1956.6770782347273\n",
      "1900 test accuracy : 0.415\n",
      "1900 test loss     : 1967.192245541305\n",
      "1910 test accuracy : 0.413\n",
      "1910 test loss     : 1970.669987306181\n",
      "1920 test accuracy : 0.414\n",
      "1920 test loss     : 1977.332781574465\n",
      "1930 test accuracy : 0.413\n",
      "1930 test loss     : 1982.4035020022995\n",
      "1940 test accuracy : 0.412\n",
      "1940 test loss     : 1982.6910734116088\n",
      "1950 test accuracy : 0.415\n",
      "1950 test loss     : 1988.0209407494665\n",
      "1960 test accuracy : 0.415\n",
      "1960 test loss     : 1990.2524351955499\n",
      "1970 test accuracy : 0.416\n",
      "1970 test loss     : 1995.1802612164065\n",
      "1980 test accuracy : 0.417\n",
      "1980 test loss     : 2003.1131330155144\n",
      "1990 test accuracy : 0.415\n",
      "1990 test loss     : 2003.1521085167956\n",
      "2000 test accuracy : 0.414\n",
      "2000 test loss     : 2008.7353062991667\n",
      "2010 test accuracy : 0.414\n",
      "2010 test loss     : 2014.1307604104886\n",
      "2020 test accuracy : 0.415\n",
      "2020 test loss     : 2019.0063750069196\n",
      "2030 test accuracy : 0.416\n",
      "2030 test loss     : 2023.5172327107232\n",
      "2040 test accuracy : 0.414\n",
      "2040 test loss     : 2025.8143363625893\n",
      "2050 test accuracy : 0.413\n",
      "2050 test loss     : 2033.1829459807104\n",
      "2060 test accuracy : 0.414\n",
      "2060 test loss     : 2034.2946843965394\n",
      "2070 test accuracy : 0.417\n",
      "2070 test loss     : 2042.1304809348997\n",
      "2080 test accuracy : 0.416\n",
      "2080 test loss     : 2047.8092581382925\n",
      "2090 test accuracy : 0.417\n",
      "2090 test loss     : 2053.18396344446\n",
      "2100 test accuracy : 0.412\n",
      "2100 test loss     : 2056.366208806636\n",
      "2110 test accuracy : 0.416\n",
      "2110 test loss     : 2061.4163216810066\n",
      "2120 test accuracy : 0.417\n",
      "2120 test loss     : 2060.346875219425\n",
      "2130 test accuracy : 0.415\n",
      "2130 test loss     : 2066.8318054235006\n",
      "2140 test accuracy : 0.417\n",
      "2140 test loss     : 2070.802862801828\n",
      "2150 test accuracy : 0.417\n",
      "2150 test loss     : 2072.7740522228605\n",
      "2160 test accuracy : 0.417\n",
      "2160 test loss     : 2079.6646249311325\n",
      "2170 test accuracy : 0.418\n",
      "2170 test loss     : 2084.3003362568174\n",
      "2180 test accuracy : 0.417\n",
      "2180 test loss     : 2091.287870017461\n",
      "2190 test accuracy : 0.419\n",
      "2190 test loss     : 2095.211493869723\n",
      "2200 test accuracy : 0.418\n",
      "2200 test loss     : 2097.872175781501\n",
      "2210 test accuracy : 0.416\n",
      "2210 test loss     : 2104.0403159209973\n",
      "2220 test accuracy : 0.417\n",
      "2220 test loss     : 2110.4133603447995\n",
      "2230 test accuracy : 0.412\n",
      "2230 test loss     : 2110.6846786772235\n",
      "2240 test accuracy : 0.413\n",
      "2240 test loss     : 2113.94110874521\n",
      "2250 test accuracy : 0.416\n",
      "2250 test loss     : 2117.949102070616\n",
      "2260 test accuracy : 0.412\n",
      "2260 test loss     : 2123.816254704485\n",
      "2270 test accuracy : 0.413\n",
      "2270 test loss     : 2131.4086214592726\n",
      "2280 test accuracy : 0.413\n",
      "2280 test loss     : 2131.118505121526\n",
      "2290 test accuracy : 0.415\n",
      "2290 test loss     : 2137.9811441432776\n",
      "2300 test accuracy : 0.412\n",
      "2300 test loss     : 2143.5043810615075\n",
      "2310 test accuracy : 0.413\n",
      "2310 test loss     : 2147.7019987561307\n",
      "2320 test accuracy : 0.411\n",
      "2320 test loss     : 2152.5495628525673\n",
      "2330 test accuracy : 0.412\n",
      "2330 test loss     : 2154.946430486863\n",
      "2340 test accuracy : 0.41\n",
      "2340 test loss     : 2158.3587897785133\n",
      "2350 test accuracy : 0.411\n",
      "2350 test loss     : 2161.1604429014055\n",
      "2360 test accuracy : 0.413\n",
      "2360 test loss     : 2164.194247980509\n",
      "2370 test accuracy : 0.412\n",
      "2370 test loss     : 2170.937692887502\n",
      "2380 test accuracy : 0.412\n",
      "2380 test loss     : 2175.5791595024198\n",
      "2390 test accuracy : 0.41\n",
      "2390 test loss     : 2180.1357517395018\n",
      "2400 test accuracy : 0.413\n",
      "2400 test loss     : 2185.3017646443786\n",
      "2410 test accuracy : 0.411\n",
      "2410 test loss     : 2187.5413743094346\n",
      "2420 test accuracy : 0.412\n",
      "2420 test loss     : 2192.8568051253765\n",
      "2430 test accuracy : 0.411\n",
      "2430 test loss     : 2196.340269727743\n",
      "2440 test accuracy : 0.408\n",
      "2440 test loss     : 2201.1408388700734\n",
      "2450 test accuracy : 0.413\n",
      "2450 test loss     : 2205.8621023864785\n",
      "2460 test accuracy : 0.41\n",
      "2460 test loss     : 2210.5943276586313\n",
      "2470 test accuracy : 0.413\n",
      "2470 test loss     : 2215.0446280041797\n",
      "2480 test accuracy : 0.41\n",
      "2480 test loss     : 2215.1293702699472\n",
      "2490 test accuracy : 0.411\n",
      "2490 test loss     : 2220.402541642497\n",
      "2500 test accuracy : 0.41\n",
      "2500 test loss     : 2224.074793995896\n",
      "2510 test accuracy : 0.409\n",
      "2510 test loss     : 2229.572039198809\n",
      "2520 test accuracy : 0.407\n",
      "2520 test loss     : 2231.216189380627\n",
      "2530 test accuracy : 0.41\n",
      "2530 test loss     : 2233.899149082102\n",
      "2540 test accuracy : 0.409\n",
      "2540 test loss     : 2241.966750827103\n",
      "2550 test accuracy : 0.409\n",
      "2550 test loss     : 2243.808427284194\n",
      "2560 test accuracy : 0.409\n",
      "2560 test loss     : 2247.978139036316\n",
      "2570 test accuracy : 0.409\n",
      "2570 test loss     : 2252.82008436676\n",
      "2580 test accuracy : 0.409\n",
      "2580 test loss     : 2256.529084858704\n",
      "2590 test accuracy : 0.407\n",
      "2590 test loss     : 2258.1739894407006\n",
      "2600 test accuracy : 0.407\n",
      "2600 test loss     : 2262.870203569787\n",
      "2610 test accuracy : 0.408\n",
      "2610 test loss     : 2266.5442893636805\n",
      "2620 test accuracy : 0.409\n",
      "2620 test loss     : 2270.9485748758925\n",
      "2630 test accuracy : 0.408\n",
      "2630 test loss     : 2274.173091975597\n",
      "2640 test accuracy : 0.407\n",
      "2640 test loss     : 2280.7231787697765\n",
      "2650 test accuracy : 0.408\n",
      "2650 test loss     : 2282.1512623272524\n",
      "2660 test accuracy : 0.407\n",
      "2660 test loss     : 2287.6041202962797\n",
      "2670 test accuracy : 0.41\n",
      "2670 test loss     : 2291.1796376172133\n",
      "2680 test accuracy : 0.41\n",
      "2680 test loss     : 2293.50098749581\n",
      "2690 test accuracy : 0.407\n",
      "2690 test loss     : 2295.1541089131697\n",
      "2700 test accuracy : 0.407\n",
      "2700 test loss     : 2299.015388894651\n",
      "2710 test accuracy : 0.407\n",
      "2710 test loss     : 2302.438501478292\n",
      "2720 test accuracy : 0.407\n",
      "2720 test loss     : 2306.4605463554954\n",
      "2730 test accuracy : 0.404\n",
      "2730 test loss     : 2309.9883504296363\n",
      "2740 test accuracy : 0.407\n",
      "2740 test loss     : 2314.1540760591115\n",
      "2750 test accuracy : 0.406\n",
      "2750 test loss     : 2316.7900946200552\n",
      "2760 test accuracy : 0.405\n",
      "2760 test loss     : 2321.460724674541\n",
      "2770 test accuracy : 0.407\n",
      "2770 test loss     : 2324.2335914776686\n",
      "2780 test accuracy : 0.409\n",
      "2780 test loss     : 2327.982733224191\n",
      "2790 test accuracy : 0.411\n",
      "2790 test loss     : 2331.7482180425623\n",
      "2800 test accuracy : 0.406\n",
      "2800 test loss     : 2336.4104410444984\n",
      "2810 test accuracy : 0.41\n",
      "2810 test loss     : 2338.078462830879\n",
      "2820 test accuracy : 0.408\n",
      "2820 test loss     : 2343.768927350083\n",
      "2830 test accuracy : 0.408\n",
      "2830 test loss     : 2347.002932127517\n",
      "2840 test accuracy : 0.407\n",
      "2840 test loss     : 2350.8128203659403\n",
      "2850 test accuracy : 0.407\n",
      "2850 test loss     : 2355.6765873994486\n",
      "2860 test accuracy : 0.407\n",
      "2860 test loss     : 2357.113154303662\n",
      "2870 test accuracy : 0.405\n",
      "2870 test loss     : 2359.8504646739684\n",
      "2880 test accuracy : 0.404\n",
      "2880 test loss     : 2364.5626054239046\n",
      "2890 test accuracy : 0.407\n",
      "2890 test loss     : 2365.5001806630858\n",
      "2900 test accuracy : 0.408\n",
      "2900 test loss     : 2371.0804404500877\n",
      "2910 test accuracy : 0.406\n",
      "2910 test loss     : 2374.0331471827\n",
      "2920 test accuracy : 0.406\n",
      "2920 test loss     : 2377.9399983974345\n",
      "2930 test accuracy : 0.404\n",
      "2930 test loss     : 2381.605345817887\n",
      "2940 test accuracy : 0.407\n",
      "2940 test loss     : 2385.5494050020793\n",
      "2950 test accuracy : 0.404\n",
      "2950 test loss     : 2388.1779815757905\n",
      "2960 test accuracy : 0.403\n",
      "2960 test loss     : 2391.0330088003047\n",
      "2970 test accuracy : 0.408\n",
      "2970 test loss     : 2393.6688928974986\n",
      "2980 test accuracy : 0.406\n",
      "2980 test loss     : 2397.1676280158927\n",
      "2990 test accuracy : 0.404\n",
      "2990 test loss     : 2402.803506161149\n"
     ]
    }
   ],
   "source": [
    "history = {'val_acc': [],'val_loss': []} #기록해서 그림 그리자!\n",
    "\n",
    "#코드를 보며 epoch, batch에 대해서 이해해봅시다.\n",
    "for i in range(epoch_size):\n",
    "    for j in range(N//batch_size):\n",
    "        batch_mask = np.random.choice(N, batch_size) #이번 배치에서 쓸 데이터들 인덱스 추출\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = y_train[batch_mask]\n",
    "        \n",
    "        nn.backward(x_batch, t_batch, 1e-7) # 가중치 갱신\n",
    "    \n",
    "    #accuracy와 loss를 기록해둡시다.\n",
    "    history[\"val_acc\"].append(nn.accuracy(x_test, y_test))\n",
    "    history[\"val_loss\"].append(nn.forward(x_test, y_test))\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i, \"test accuracy :\", nn.accuracy(x_test, y_test))\n",
    "        print(i, \"test loss     :\", nn.forward(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그림 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나의 최고 validation loss :  0.433\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax_acc = fig.add_subplot(111)\n",
    "\n",
    "ax_acc.plot(range(epoch_size), history['val_acc'], label='정확도(%)', color='darkred')\n",
    "#plt.text(3, 14.7, \"<----------------정확도(%)\", verticalalignment='top', horizontalalignment='right')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Validation Accuracy(%)')\n",
    "ax_acc.grid(linestyle='--', color='lavender')\n",
    "ax_loss = ax_acc.twinx()\n",
    "ax_loss.plot(range(epoch_size), history['val_loss'], label='오차', color='darkblue')\n",
    "#plt.text(3, 2.2, \"<----------------오차\", verticalalignment='top', horizontalalignment='left')\n",
    "plt.ylabel('Validation Error')\n",
    "ax_loss.yaxis.tick_right()\n",
    "ax_loss.grid(linestyle='--', color='lavender')\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()\n",
    "\n",
    "# 나의 최고 validation accuracy는? 두구두구~\n",
    "print(\"나의 최고 validation loss : \",max(history['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론\n",
    "1. epoch를 3000으로 주었더니 로스가 다시 올라가는 모습을 보였다. 근데 로스는 올라가지만 그에비해 accuracy는 크게 떨어지지 않았다. 왜 그런 것일까?....\n",
    "2. loss는 이렇게 다시 올라가고 있지만 학습을 계속 진행하면 다시 떨어질 수도 있지 않을까? 지금 나온 저것이 지역해일 수도 있지 않을까? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
